{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# f-scLVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we illustrate how f-scLVM can be used to identify biological processes driving variability between cells. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load some modules and set some directories, we here use the same data as before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./')\n",
    "import os\n",
    "import scipy as SP\n",
    "import cPickle as pickle\n",
    "import fscLVM.core as fscLVM\n",
    "import fscLVM.utils.utils as utils\n",
    "import h5py\n",
    "#from utils import *\n",
    "%pylab inline\n",
    "\n",
    "data_dir = './data/'\n",
    "out_base = './../results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f-scLVM expects a hdf file containing the normalised, log transformed gene expression data as well as a set of annotations. We have put this information together in hdf files. Start off by running the notebook for the T-cell data analysed in the scLVM notebook. Next, use different annotations (REACTOME) instead of MSigDB). Finally, have a look at a data-set of mESC cells staged by cell cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dFile = 'Tcell_sfERCC.hdf5'\n",
    "#name of annotation\n",
    "anno = 'MSigDB'\n",
    "\n",
    "#specify noise model\n",
    "noise = 'gauss'\n",
    "\n",
    "#number of hidden (unannotated variables)\n",
    "nHidden = 1\n",
    "#indices of known covariates\n",
    "idx_known = []\n",
    "\n",
    "idxCol=[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to load the relevant data from the hdf5 file. minGenes is the minimum number of genes in a pathway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = utils.load_data(dFile, annotation=anno, minGenes=15, nHidden=nHidden, doFast=True, noise=noise, data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we initialise the model and iterate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y = data['Y']\n",
    "\n",
    "#use pre-training to determine initial update order \n",
    "init_params = {}\n",
    "init_params['noise'] = noise\n",
    "init_params['iLatent'] = SP.where(data['terms']=='hidden')[0]\n",
    "\n",
    "#get initial ordering via pre-training\n",
    "Ilabel = utils.preTrain(Y, data['terms'], data['pi'],init_params)\n",
    "\n",
    "#re-order terms\n",
    "print \"Initial order\", data['terms'][Ilabel]\n",
    "terms = data['terms'][Ilabel]\n",
    "pi = data['pi'][:,Ilabel]\n",
    "\n",
    "\n",
    "#initialise model\n",
    "init={'init_data':fscLVM.CGauss(Y),'Pi':pi,'init_factors':init_params}\n",
    "priors = {'Eps': {'priors':[1E-3,1E-3]}}\n",
    "FA = fscLVM.CSparseFA(components=pi.shape[1], priors=priors,verbose=True)   \n",
    "FA.init(**init) \n",
    "\n",
    "#iterate\n",
    "FA.iterate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We then plot results. First, we show the relevance of the terms; then we plot the 2 most important factors, in this case G2M Checkpoint and P53 Pathway. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#scatter plot of two most important factors\n",
    "utils.plotTerms(FA, terms=terms)\n",
    "\n",
    "dataFile = h5py.File(os.path.join(data_dir, dFile), 'r')\n",
    "utils.plotFactors(0,1,FA,lab = dataFile['Known'][:][0,:]+2*dataFile['Known'][:][1,:], \n",
    "                  terms=terms, isCont=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can look how a Bayesian GPLVM looks like when we regress out confounding facotrs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import GPy\n",
    "#Get model residuals\n",
    "Ycorr = utils.regressOut(Y, idx=[0,2,6],FA=FA)\n",
    "\n",
    "## Model optimization\n",
    "Ystd = Ycorr-Ycorr.mean(0)\n",
    "#Ystd/=Ystd.std(0)\n",
    "input_dim = 2 # How many latent dimensions to use\n",
    "kern = GPy.kern.RBF(input_dim,ARD=True) # ARD kernel\n",
    "m = GPy.models.BayesianGPLVM(Ystd, input_dim=input_dim, kernel=kern, num_inducing=40)\n",
    "m.optimize('scg', messages=1, max_iters=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pylab as PL\n",
    "PL.scatter(m.X.mean[:,0], m.X.mean[:,1], 40, dataFile['Known'][3,:])\n",
    "PL.xlabel('Component 1')\n",
    "PL.ylabel('Component 2')\n",
    "PL.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print the terms in order\n",
    "print terms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Q1: repeat this using a differnet annotation file by replacing MSigDB with REACTOME\n",
    "\n",
    "Q2: Repeat the analysis on a different dataset of staged mESCs - which factors are most relevant now? What happens when you regress out cell cycle?\n",
    "Hint: use the hdf5 file Buettneretal.hdf5\n",
    "\n",
    "Q2.2: Colour the most imporant factors by cell cycle.\n",
    "Hint: use dataFile['Known'][:][0,:]+2*dataFile['Known'][:][1,:] as color argument and plot the 2 most important components in the scatter plot "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
